{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc8953f9-53d8-4233-8c67-975d57ff55c0",
   "metadata": {},
   "source": [
    "# Business Question:\n",
    "## How do rising housing costs, as measured by home values, influence homelessness rates in San Francisco, and what interventions can mitigate this trend?\n",
    "This study analyzes historical trends in home values and their correlation with homelessness rates in San Francisco. By identifying key affordability challenges, we aim to explore policy interventions, such as zoning reforms and affordable housing initiatives, to mitigate displacement and improve housing stability. Insights from this research will inform strategies for sustainable and inclusive urban development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff3f6c0-625b-4df4-aae4-075100791818",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries \n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from scipy.interpolate import CubicSpline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ae1673-35cd-455c-be2e-cf5c61e7119c",
   "metadata": {},
   "source": [
    "# Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0932c7b9-3809-49fb-ac58-bcc956434972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the uploaded dataset to inspect its structure and contents\n",
    "file_path = '/Users/diana/Babson MSBA/Advance Programming for BA/Phyton/raw original data/Metro_zhvi_uc_condo_tier_0.33_0.67_sm_sa_month.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the dataset to understand its structure\n",
    "data.head(), data.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc2e537-611d-48d0-919c-8abf7618742d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in each column\n",
    "missing_values = data.isnull().sum()\n",
    "\n",
    "print(\"Missing values per column:\")\n",
    "print(missing_values)\n",
    "\n",
    "\n",
    "# Identify columns that should be numeric but are stored as objects\n",
    "for col in data.columns:\n",
    "    if data[col].dtype == 'object':  # Checking text-based columns\n",
    "        try:\n",
    "            data[col].astype(float)  # Attempt conversion\n",
    "            print(f\"‚ö†Ô∏è Column '{col}' should be numeric but is stored as object.\")\n",
    "        except ValueError:\n",
    "            pass  # Column contains non-numeric values, so it's fine as object\n",
    "\n",
    "# List numeric columns\n",
    "numeric_cols = data.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "# Find non-numeric values in numeric columns\n",
    "for col in numeric_cols:\n",
    "    invalid_values = data[~data[col].astype(str).str.replace('.', '', 1).str.isnumeric()]\n",
    "    if not invalid_values.empty:\n",
    "        print(f\"üö® Non-numeric values found in '{col}':\")\n",
    "        print(invalid_values[[col]])\n",
    "# Identify potential date columns\n",
    "for col in data.columns:\n",
    "    try:\n",
    "        pd.to_datetime(data[col])\n",
    "        print(f\"üìÖ Column '{col}' looks like a date but is stored as '{data[col].dtype}'.\")\n",
    "    except Exception:\n",
    "        pass  # Not a date column\n",
    "# Convert a column to numeric\n",
    "data[\"column_name\"] = pd.to_numeric(data[\"column_name\"], errors='coerce')\n",
    "\n",
    "# Convert a column to datetime\n",
    "data[\"date_column\"] = pd.to_datetime(data[\"date_column\"], errors='coerce')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d48ed42-0b56-4136-b8f2-4f8794c9aab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify metadata columns (non-date columns)\n",
    "metadata_cols = ['RegionID', 'SizeRank', 'RegionName', 'RegionType', 'StateName']\n",
    "\n",
    "# Identify actual date columns (all other columns are dates)\n",
    "date_cols = [col for col in data.columns if col not in metadata_cols]\n",
    "\n",
    "# Reshape the dataset into a long format for time-series analysis\n",
    "data_melted = data.melt(id_vars=metadata_cols, \n",
    "                         var_name=\"Date\", \n",
    "                         value_name=\"HomeValue\")\n",
    "\n",
    "# Convert Date column to datetime format\n",
    "data_melted[\"Date\"] = pd.to_datetime(data_melted[\"Date\"])\n",
    "\n",
    "# Display the first few rows of the reshaped dataset\n",
    "data_melted.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9085ffe9-f808-41a9-95b7-7096bd67ad7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set figure size for better visualization\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Create a box plot to detect outliers in home values\n",
    "sns.boxplot(x=data_melted[\"HomeValue\"])\n",
    "\n",
    "# Add title and labels\n",
    "plt.title(\"Box Plot of Home Values\", fontsize=14)\n",
    "plt.xlabel(\"Home Value\", fontsize=12)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b061d6e-1a19-4cf7-a592-bb0a47e97d07",
   "metadata": {},
   "source": [
    "# San Francisco, CA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37a10ac-7375-452c-a6fa-ceafe841b4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the dataset for San Francisco\n",
    "sf_data = data_melted[data_melted[\"RegionName\"] == \"San Francisco, CA\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad533917-fee4-4299-9bf8-2e1aa004d66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Plot home value trends in San Francisco\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.lineplot(data=sf_data, x=\"Date\", y=\"HomeValue\", label=\"Home Value\", color=\"blue\")\n",
    "plt.title(\"San Francisco Home Value Trends (2000-2024)\", fontsize=14)\n",
    "plt.xlabel(\"Year\", fontsize=12)\n",
    "plt.ylabel(\"Home Value ($)\", fontsize=12)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf74ee2-2b14-4e78-850b-a40f7035a726",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_melted.head())  # This should display the first few rows\n",
    "print(data_melted.info())  # This should confirm columns and data types\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17745010-d91e-4e0d-963c-0ac781c2628b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_melted[\"RegionName\"].unique())  # Check available region names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052b1c86-9f3a-4f03-a3a9-cb27d21beab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_data = data_melted[data_melted[\"RegionName\"] == \"San Francisco, CA\"]\n",
    "ca_data = data_melted[data_melted[\"StateName\"] == \"CA\"]  # Get all California regions\n",
    "\n",
    "# Aggregate California's home values by averaging all metro areas in the state\n",
    "ca_avg = ca_data.groupby(\"Date\")[\"HomeValue\"].mean().reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f191188-154b-49d3-ab14-523e93c3658f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot San Francisco\n",
    "sns.lineplot(data=sf_data, x=\"Date\", y=\"HomeValue\", label=\"San Francisco, CA\", color=\"blue\", linewidth=2)\n",
    "\n",
    "# Plot California State (Averaged)\n",
    "sns.lineplot(data=ca_avg, x=\"Date\", y=\"HomeValue\", label=\"California State (Average)\", color=\"red\", linewidth=2)\n",
    "\n",
    "# Add title and labels\n",
    "plt.title(\"Comparison of Home Value Trends: San Francisco vs. California\", fontsize=14)\n",
    "plt.xlabel(\"Year\", fontsize=12)\n",
    "plt.ylabel(\"Home Value ($)\", fontsize=12)\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b210398-c9c6-4623-b702-f5f30c53b3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/Users/diana/Babson MSBA/Advance Programming for BA/Phyton/raw original data/Metro_zhvi_uc_condo_tier_0.33_0.67_sm_sa_month.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1a5bbe-e7bf-464d-a876-fb0580aeeb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the dataset\n",
    "file_path = '/Users/diana/Babson MSBA/Advance Programming for BA/Phyton/raw original data/Metro_zhvi_uc_condo_tier_0.33_0.67_sm_sa_month.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Identify metadata columns\n",
    "metadata_cols = ['RegionID', 'SizeRank', 'RegionName', 'RegionType', 'StateName']\n",
    "\n",
    "# Identify actual date columns (all columns except metadata)\n",
    "date_cols = [col for col in data.columns if col not in metadata_cols]\n",
    "\n",
    "# Reshape the dataset into long format\n",
    "data_melted = data.melt(id_vars=metadata_cols, var_name=\"Date\", value_name=\"HomeValue\")\n",
    "\n",
    "# Convert Date column to datetime format\n",
    "data_melted[\"Date\"] = pd.to_datetime(data_melted[\"Date\"], errors='coerce')\n",
    "\n",
    "# Filter for San Francisco\n",
    "sf_data = data_melted[data_melted[\"RegionName\"] == \"San Francisco, CA\"].copy()\n",
    "\n",
    "# Set Date as index and keep only HomeValue\n",
    "sf_data = sf_data.set_index(\"Date\")[[\"HomeValue\"]].dropna()\n",
    "\n",
    "# Train the ARIMA model\n",
    "arima_model = ARIMA(sf_data, order=(2, 1, 2))  # Adjust order if needed\n",
    "arima_result = arima_model.fit()\n",
    "\n",
    "# Forecast for the next 12 months\n",
    "forecast = arima_result.forecast(steps=12)\n",
    "\n",
    "# Create future dates for visualization\n",
    "future_dates = pd.date_range(start=sf_data.index[-1], periods=12, freq='M')\n",
    "\n",
    "# Plot actual vs. forecasted values\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(sf_data, label=\"Actual Home Values\", color=\"blue\")\n",
    "plt.plot(future_dates, forecast, label=\"Forecast\", color=\"red\", linestyle=\"dashed\")\n",
    "\n",
    "# Add title and labels\n",
    "plt.title(\"Housing Value Forecast for San Francisco (ARIMA Model)\", fontsize=14)\n",
    "plt.xlabel(\"Year\", fontsize=12)\n",
    "plt.ylabel(\"Home Value ($)\", fontsize=12)\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7253299b-c91b-4176-a3f3-461ee2111ab1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
